{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tensor操作方法\n",
    "1.6版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 按照索引操作tensor\n",
    "gather方法的作用，index代表索引位置，dim指定具体行还是列。比如以下例子[1,2,3;4,5,6]，指定dim=1，那么索引就是列号。index的大小就是输出的大小，比如index是[0,1;2,0]，那么看index第一行，0列指元素1，1列指元素2，同理，第二行为6，4，这样输出就为[1,2;6,4]，即可理解gather的含义。\n",
    "\n",
    "gather在one-hot为输出的多分类问题中，可以把最大值坐标作为index传进去，然后提取到每一行的正确预测结果，这也是gather可能的一个作用。\n",
    "\n",
    "torch.gather(input, dim, index, out=None)：在指定维度上按照索引赋值输出tensor。输入与输出大小一致。\n",
    "\n",
    "torch.index_select(input, dim, index, out=None)：选出一维度的一些slice组合成新的tensor。指定维度的大小与index大小一致。\n",
    "\n",
    "torch.masked_select(input, mask, out=None)：按照mask输出一个一维的tensor。\n",
    "\n",
    "torch.take(input, indices)：将输入看成1D tensor，按照索引得到输出。输出大小与index大小一致。\n",
    "\n",
    "torch.nonzero(input, out=None)：输出非0 元素的坐标。\n",
    "\n",
    "torch.where(condition, x, y)：按照条件从x和y中选出满足条件的元素组成新的tensor。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "tensor([[1, 2],\n",
      "        [6, 4]])\n",
      "tensor([[1, 5, 6],\n",
      "        [1, 2, 3]])\n"
     ]
    }
   ],
   "source": [
    "b = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "print(b)\n",
    "index_1 = torch.tensor([[0, 1], [2, 0]], dtype=torch.long)\n",
    "index_2 = torch.tensor([[0, 1, 1], [0, 0, 0]], dtype=torch.long)\n",
    "print(torch.gather(b, dim=1, index=index_1))\n",
    "print(torch.gather(b, dim=0, index=index_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 张量镜像翻转torch.flip\n",
    "按照给定维度翻转张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0, 1],\n",
      "         [2, 3]],\n",
      "\n",
      "        [[4, 5],\n",
      "         [6, 7]]])\n",
      "tensor([[[1, 0],\n",
      "         [3, 2]],\n",
      "\n",
      "        [[5, 4],\n",
      "         [7, 6]]])\n",
      "tensor([[[6, 7],\n",
      "         [4, 5]],\n",
      "\n",
      "        [[2, 3],\n",
      "         [0, 1]]])\n",
      "tensor([[[3, 2],\n",
      "         [1, 0]],\n",
      "\n",
      "        [[7, 6],\n",
      "         [5, 4]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(8).view(2, 2, 2)\n",
    "print(x)\n",
    "print(torch.flip(x, [2]))\n",
    "print(torch.flip(x, [0, 1]))\n",
    "print(torch.flip(x,[1,2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 张量打平torch.flatten\n",
    "假设t的形状是：(2,4,3,5,6)，则torch.flatten(t, 1, 3).shape 的结果为 (2, 60, 6)。\n",
    "\n",
    "将索引为 start_dim 和 end_dim 之间（包括该位置）的数量相乘，其余位置不变。\n",
    "\n",
    "因为默认 start_dim=0，end_dim=-1，所以 torch.flatten(t) 返回只有一维的数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 3, 5, 6])\n",
      "torch.Size([2, 60, 6])\n",
      "torch.Size([720])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2,4,3,5,6)\n",
    "print(x.shape)\n",
    "print(torch.flatten(x, 1, 3).shape)\n",
    "print(torch.flatten(x).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 张量拼接torch.cat\n",
    "在指定的维度dim上对tensor序列进行连接操作，按照已经存在的维度进行。\n",
    "\n",
    "torch.stack(seq, dim=0, out=None)：按照新的维度进行concatenate，它会增加一个维度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3645, -1.8158,  0.2189],\n",
      "        [-1.0904, -0.7776,  1.1962]])\n",
      "tensor([[-0.3645, -1.8158,  0.2189],\n",
      "        [-1.0904, -0.7776,  1.1962],\n",
      "        [-0.3645, -1.8158,  0.2189],\n",
      "        [-1.0904, -0.7776,  1.1962]])\n",
      "tensor([[-0.3645, -1.8158,  0.2189, -0.3645, -1.8158,  0.2189],\n",
      "        [-1.0904, -0.7776,  1.1962, -1.0904, -0.7776,  1.1962]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2, 3)\n",
    "print(x)\n",
    "print(torch.cat((x, x), 0))\n",
    "print(torch.cat((x, x), 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 扩大张量torch.Tensor.expand\n",
    "返回张量的一个新视图，可以将张量的单个维度扩大为更大的尺寸。\n",
    "\n",
    "张量也可以扩大为更高维，新增加的维度将附在前面。扩大张量不需要分配新内存，仅仅是新建一个张量的视图。任意一个一维张量在不分配新内存情况下都可以扩展为任意的维度。\n",
    "\n",
    "传入-1则意味着维度扩大不涉及这个维度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1],\n",
      "        [2],\n",
      "        [3]])\n",
      "tensor([[1, 1, 1, 1],\n",
      "        [2, 2, 2, 2],\n",
      "        [3, 3, 3, 3]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1], [2], [3]])\n",
    "print(x)\n",
    "y = x.expand(3, 4)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 张量压缩torch.squeeze\n",
    "去除张量中数值为1的维度，并返回新的张量。\n",
    "\n",
    "当通过dim参数指定维度时，维度压缩操作只会在指定的维度上进行。\n",
    "\n",
    "如果一个张量只有1个维度，那么它不会受到上述方法的影响。\n",
    "\n",
    "输出的张量与原张量共享内存，如果改变其中的一个，另一个也会改变。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 2, 1, 2])\n",
      "torch.Size([2, 2, 2])\n",
      "torch.Size([2, 1, 2, 1, 2])\n",
      "torch.Size([2, 2, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(2, 1, 2, 1, 2)\n",
    "print(x.size())\n",
    "y = torch.squeeze(x)\n",
    "print(y.size())\n",
    "y = torch.squeeze(x, 0)\n",
    "print(y.size())\n",
    "y = torch.squeeze(x, 1)\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 重复张量torch.Tensor.repeat\n",
    "沿着指定的维度重复张量。不同于expand()方法，本函数复制的是张量中的数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3., 1., 2., 3.],\n",
      "        [1., 2., 3., 1., 2., 3.],\n",
      "        [1., 2., 3., 1., 2., 3.],\n",
      "        [1., 2., 3., 1., 2., 3.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor([1, 2, 3])\n",
    "print(x.repeat(4, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 缩小张量 torch.Tensor.narrow\n",
    "返回一个经过缩小后的张量，操作的维度由dimension指定。\n",
    "\n",
    "缩小范围是从start开始到start+length，执行本方法的张量与返回的张量共享相同的底层内存。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "tensor([[2, 3],\n",
      "        [5, 6],\n",
      "        [8, 9]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "print(x.narrow(0, 0, 2))\n",
    "print(x.narrow(1, 1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 张量变形 torch.Tensor.view\n",
    "返回一个有相同数据但是不同形状的新的张量。\n",
    "\n",
    "返回的张量必须与原张量有相同的数据和相同的元素个数，但是可以有不同的尺寸。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4])\n",
      "torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4, 4)\n",
    "print(x.size())\n",
    "y = x.view(16)\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 重设张量尺寸torch.Tensor.resize_\n",
    "将张量的尺寸调整为指定的大小。如果元素个数比当前的内存大小大，就将底层存储大小调整为与新元素数目一致的大小。\n",
    "\n",
    "如果元素个数比当前内存小，则底层存储不会被改变。原来张量中被保存下来的元素将保持不变，但新内存将不会被初始化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6]])\n",
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
    "print(x)\n",
    "x.resize_(3, 2)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 置换张量维度torch.Tensor.permute\n",
    "将执行本方法的张量的维度换位。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 5])\n",
      "torch.Size([5, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2, 3, 5)\n",
    "print(x.size())\n",
    "print(x.permute(2, 0, 1).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 查看张量单个元素的字节数 torch.Tensor.element_size\n",
    "查看某类型张量单个元素的字节数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.FloatTensor().element_size()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
